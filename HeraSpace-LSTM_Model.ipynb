{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, json \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from time import sleep\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model with Multi-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Sample data with multiple inputs and outputs #\n",
    "################################################\n",
    "\n",
    "def sample_time_series_roll(N, T, seed = 1337):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Inputs\n",
    "    x1 = np.array(np.random.uniform(size=2*T*N)).reshape(2*N, T)\n",
    "    x2 = np.array(np.random.uniform(size=2*T*N)).reshape(2*N, T)\n",
    "    x3 = np.array(np.random.uniform(size=2*T*N)).reshape(2*N, T)\n",
    "    x4 = np.array(np.random.uniform(size=2*T*N)).reshape(2*N, T)\n",
    "    \n",
    "    # Outputs\n",
    "    y1 = np.roll(x1, 2) # y1[t] = x1[t-2]\n",
    "    y2 = np.roll(x2, 1) * np.roll(x3, 2) # y2[t] = x2[t-1]*x3[t-2]\n",
    "    y3 = np.roll(x4, 3) # y3[t] = x4[t-3]\n",
    "   \n",
    "   \n",
    "    # Training/test sets\n",
    "    x1_train, x2_train, x3_train, x4_train = [x[0:N] for x in [x1, x2, x3, x4]]\n",
    "    x1_test, x2_test, x3_test, x4_test = [x[N:2*N] for x in [x1, x2, x3, x4]]\n",
    "    y1_train, y2_train, y3_train = [y[0:N] for y in [y1, y2, y3]]\n",
    "    y1_test, y2_test, y3_test = [y[N:2*N] for y in [y1, y2, y3]]\n",
    "    \n",
    "    return(x1_train, x2_train, x3_train, x4_train, x1_test, x2_test, x3_test, \n",
    "           x4_test,y1_train, y2_train, y3_train,y1_test, y2_test, y3_test)\n",
    "\n",
    "def sample_time_series_1(N, T, seed = 1337):\n",
    "    np.random.seed(seed)\n",
    "    ##\n",
    "    # Inputs\n",
    "    ##\n",
    "    x = np.zeros(2*N*T).reshape(2*N, T)\n",
    "    one_indexes = np.random.choice(a = 2*N, size = N, replace = False)\n",
    "    x[one_indexes, 0] = 1 # very long term memory\n",
    "    ##\n",
    "    # Outputs\n",
    "    ##\n",
    "    y = np.repeat(x[:,0], T).reshape(2*N, T)\n",
    "    ##\n",
    "    # Training/test sets\n",
    "    ##\n",
    "    x_train = x[0:N]\n",
    "    x_test = x[N:2*N]\n",
    "    y_train = y[0:N]\n",
    "    y_test = y[N:2*N]\n",
    "    return(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "# Plotting loss and val_loss as function of epochs \n",
    "def plotting(history):\n",
    "    plt.plot(history.history['loss'], color = \"red\")\n",
    "    plt.plot(history.history['val_loss'], color = \"blue\")\n",
    "    red_patch = mpatches.Patch(color='red', label='Training')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Test')\n",
    "    plt.legend(handles=[red_patch, blue_patch])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for stateful network (i.e. for Part C) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stateful_cut(arr, batch_size, T_after_cut):\n",
    "    if len(arr.shape) != 3:\n",
    "        # N: Independent sample size,\n",
    "        # T: Time length,\n",
    "        # m: Dimension\n",
    "        print(\"ERROR: please format arr as a (N, T, m) array.\")\n",
    "    \n",
    "    N = arr.shape[0]\n",
    "    T = arr.shape[1]\n",
    "    # We need T_after_cut * nb_cuts = T\n",
    "    nb_cuts = int(T / T_after_cut)\n",
    "    if nb_cuts * T_after_cut != T:\n",
    "        print(\"ERROR: T_after_cut must divide T\")\n",
    "    \n",
    "    # We need batch_size * nb_reset = N\n",
    "    nb_reset = int(N / batch_size)\n",
    "    if nb_reset * batch_size != N:\n",
    "        print(\"ERROR: batch_size must divide N\")\n",
    "   \n",
    "    # Cutting (technical)\n",
    "    cut1 = np.split(arr, nb_reset, axis=0)\n",
    "    cut2 = [np.split(x, nb_cuts, axis=1) for x in cut1]\n",
    "    cut3 = [np.concatenate(x) for x in cut2]\n",
    "    cut4 = np.concatenate(cut3)\n",
    "    \n",
    "    return(cut4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Function to define 'Callback resetting model states' class #\n",
    "##############################################################\n",
    "# This callback will slow down computations.\n",
    "def define_reset_states_class(nb_cuts):\n",
    "    class ResetStatesCallback(Callback):\n",
    "        def __init__(self):\n",
    "            self.counter = 0\n",
    "        def on_batch_begin(self, batch, logs={}):\n",
    "            # We reset states when nb_cuts batches are completed, as\n",
    "            # shown in the after cut figure\n",
    "            if self.counter % nb_cuts == 0:\n",
    "                self.model.reset_states()\n",
    "                self.counter += 1\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            # reset states after each epoch\n",
    "            self.model.reset_states()\n",
    "    return(ResetStatesCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(i, arr, batch_size):\n",
    "    return(arr[i*batch_size:(i+1)*batch_size])\n",
    "\n",
    "def test_on_batch_stateful(model, inputs, outputs, batch_size, nb_cuts):\n",
    "    nb_batches = int(len(inputs)/batch_size)\n",
    "    sum_pred = 0\n",
    "    for i in range(nb_batches):\n",
    "        if i % nb_cuts == 0:\n",
    "            model.reset_states()\n",
    "            x = batched(i, inputs, batch_size)\n",
    "            y = batched(i, outputs, batch_size)\n",
    "            sum_pred += model.test_on_batch(x, y)\n",
    "            mean_pred = sum_pred / nb_batches\n",
    "    return(mean_pred)\n",
    "\n",
    "def define_stateful_val_loss_class(inputs, outputs, batch_size, nb_cuts):\n",
    "    class ValidationCallback(Callback):\n",
    "        def __init__(self):\n",
    "            self.val_loss = []\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            mean_pred = test_on_batch_stateful(self.model, inputs, outputs, \n",
    "            batch_size, nb_cuts)\n",
    "            print('val_loss: {:0.3e}'.format(mean_pred), end = '')\n",
    "            self.val_loss += [mean_pred]\n",
    "        def get_val_loss(self):\n",
    "            return(self.val_loss)\n",
    "    return(ValidationCallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ocean = pd.read_csv('Fish_Training_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_ocean.dropna(subset=['Lat_7_days','Lon_7_days','CPUE_7_days']).sort_values('Date').drop(['CPUE_number_per_hour','Date'],axis=1)#[train_ocean['CPUE']<300] #\n",
    "y = train_ocean.dropna(subset=['Lat_7_days','Lon_7_days','CPUE_7_days']).sort_values('Date')['CPUE_number_per_hour'] #[train_ocean['CPUE']<300]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ocean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_ocean.dropna(subset=['Lat_7_days','Lon_7_days','CPUE_7_days']).sort_values('Date')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "T = 120\n",
    "batch_size = 8 # number of time series considered together: batch_size | N\n",
    "T_after_cut = 15\n",
    "round_end = 3840\n",
    "# Inputs\n",
    "x1_f = dataset['Lat_7_days'].values[:round_end].reshape(2*N, T)\n",
    "x2_f = dataset['CPUE_7_days'].values[:round_end].reshape(2*N, T)\n",
    "x3_f = dataset['Lon_7_days'].values[:round_end].reshape(2*N, T)\n",
    "x4_f = dataset['thetao'].values[:round_end].reshape(2*N, T)\n",
    "x5_f = dataset['so'].values[:round_end].reshape(2*N, T)\n",
    "\n",
    "# Outputs\n",
    "y1_f = dataset['CPUE_number_per_hour'].values[:round_end].reshape(2*N, T)\n",
    "y2_f = dataset['Lat'].values[:round_end].reshape(2*N, T)\n",
    "y3_f = dataset['Lon'].values[:round_end].reshape(2*N, T)\n",
    "x1_f.shape == y1_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/test sets\n",
    "x1_train_f, x2_train_f, x3_train_f, x4_train_f = [x[0:N] for x in [x1_f, x2_f, x3_f, x4_f]]\n",
    "x1_test_f, x2_test_f, x3_test_f, x4_test_f = [x[N:2*N] for x in [x1_f, x2_f, x3_f, x4_f]]\n",
    "\n",
    "y1_train_f, y2_train_f, y3_train_f = [y[0:N] for y in [y1_f, y2_f, y3_f]] #! Delete last [0] brackets if more than one output\n",
    "y1_test_f, y2_test_f, y3_test_f = [y[N:2*N] for y in [y1_f, y2_f, y3_f]] #! Delete last [0] brackets if more than one output\n",
    "x1_train_f.shape, x1_test_f.shape, y1_train_f.shape, y1_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape each time series as (N, T, dim_in) or (N, T, dim_out)\n",
    "x_train_f = np.concatenate((x1_train_f.reshape(N, T, 1), \n",
    "                            x2_train_f.reshape(N, T, 1),\n",
    "                            x3_train_f.reshape(N, T, 1),\n",
    "                            x4_train_f.reshape(N, T, 1),\n",
    "                            #x5_train_f.reshape(N, T, 1),\n",
    "                           ), axis=2)\n",
    "\n",
    "y_train_f = np.concatenate((y1_train_f.reshape(N, T, 1),\n",
    "                            y2_train_f.reshape(N, T, 1),\n",
    "                            y3_train_f.reshape(N, T, 1),\n",
    "                            ), axis=2)\n",
    "\n",
    "x_train_f.shape, y_train_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_f = np.concatenate((x1_test_f.reshape(N, T, 1), \n",
    "                            x2_test_f.reshape(N, T, 1),\n",
    "                            x3_test_f.reshape(N, T, 1),\n",
    "                            x4_test_f.reshape(N, T, 1),\n",
    "                            #x5_test_f.reshape(N, T, 1),\n",
    "                          ), axis=2)\n",
    "\n",
    "y_test_f = np.concatenate((y1_test_f.reshape(N, T, 1),\n",
    "                            y2_test_f.reshape(N, T, 1),\n",
    "                            y3_test_f.reshape(N, T, 1),\n",
    "                            ), axis=2)\n",
    "\n",
    "x_test_f.shape, y_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs, inputs_test, outputs_test = \\\n",
    "  [stateful_cut(arr, batch_size, T_after_cut) for arr in \\\n",
    "  [x_train_f, y_train_f, x_test_f, y_test_f]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "dim_in = 4 # dimension of input time series\n",
    "dim_out = 3\n",
    "nb_units = 100\n",
    "model = Sequential()\n",
    "model.add(LSTM(batch_input_shape=(batch_size, None, dim_in),\n",
    "               return_sequences=True, units=nb_units, stateful=True))\n",
    "\n",
    "model.add(LSTM(30, activation='relu', return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(activation='linear', units=dim_out)))\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'rmsprop')\n",
    "\n",
    "##\n",
    "# Training\n",
    "##\n",
    "epochs = 100\n",
    "nb_reset = int(N / batch_size)\n",
    "nb_cuts = int(T / T_after_cut)\n",
    "if nb_reset > 1:\n",
    "    ResetStatesCallback = define_reset_states_class(nb_cuts)\n",
    "    ValidationCallback = define_stateful_val_loss_class(inputs_test, \n",
    "    outputs_test, \n",
    "    batch_size, nb_cuts)\n",
    "    validation = ValidationCallback()\n",
    "    history = model.fit(inputs, outputs, epochs = epochs, \n",
    "    batch_size = batch_size, shuffle=False,\n",
    "    callbacks = [ResetStatesCallback(), validation])\n",
    "    history.history['val_loss'] = ValidationCallback.get_val_loss(validation)\n",
    "else:\n",
    "    # If nb_reset = 1, we should reset states after each epoch.\n",
    "    # To improve computational speed, we can decide not to reinitialize states\n",
    "    # at all. Results are similar in this case.\n",
    "    # In the following line, states are not reinitialized at all:\n",
    "    history = model.fit(inputs, outputs, epochs = epochs, \n",
    "    batch_size = batch_size, shuffle=False,\n",
    "    validation_data=(inputs_test, outputs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising predicted and actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stateless = Sequential()\n",
    "model_stateless.add(LSTM(input_shape=(None, dim_in),\n",
    "return_sequences=True, units=nb_units))\n",
    "model_stateless.add(LSTM(30, activation='relu', return_sequences=True))\n",
    "model_stateless.add(TimeDistributed(Dense(activation='linear', units=dim_out)))\n",
    "model_stateless.compile(loss = 'mse', optimizer = 'rmsprop')\n",
    "model_stateless.set_weights(model.get_weights())\n",
    "\n",
    "## Prediction of a new set\n",
    "n = 10 # time series selected (between 0 and N-1)\n",
    "x = x_test_f[n]\n",
    "y = y_test_f[n]\n",
    "y_hat = model_stateless.predict(np.array([x]))[0]\n",
    "dim = 0 # dim=0 for y1 ; dim=1 for y2 ; dim=2 for y3.\n",
    "size = 35\n",
    "plt.plot(range(T)[0:size], y[:,dim][0:size])\n",
    "plt.plot(range(T)[0:size], y_hat[:,dim][0:size])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
